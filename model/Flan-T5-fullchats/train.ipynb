{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"puBLKXFW7-RD"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yAvxQOh1K72T"},"outputs":[],"source":["!pip install rouge_score\n","!pip install transformers\n","!pip install datasets\n","!pip install parlai\n","!pip install transformers datasets wandb\n","!pip install --upgrade accelerate\n","!parlai display_data -t msc:PersonaSummary --include-last-session True\n","!pip install --upgrade numpy\n","!pip install names\n","!pip install py7zr\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-w9yJzR8gQa"},"outputs":[],"source":["import transformers\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n","from datasets import load_dataset, load_from_disk\n","import numpy as np\n","import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TmXj2SiK8gle"},"outputs":[],"source":["max_input = 512\n","max_target = 128\n","batch_size = 3\n","model_checkpoint = \"philschmid/flan-t5-base-samsum\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6GZDB2f8-IZ"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4qYhG6Rb6MR"},"outputs":[],"source":["import names\n","#Generate random names\n","for i in range(10):\n","    rand_name = names.get_first_name()\n","    print(rand_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yGF8NLH7fIyy"},"outputs":[],"source":["from datasets import load_dataset, load_from_disk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eX8zyJxQfJVR"},"outputs":[],"source":["data = load_dataset(\"samsum\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CORjvgTQgCEt"},"outputs":[],"source":["data['train'][:2]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EjaiDUCygU_J"},"outputs":[],"source":["def getSpeakerNames():\n","  speaker_1 = names.get_first_name()\n","  speaker_2 = names.get_first_name()\n","  while(speaker_1 == speaker_2):\n","    speaker_2 = names.get_first_name()\n","  return speaker_1, speaker_2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pdJKO3CU9IVd"},"outputs":[],"source":["import re\n","import json\n","# Read the JSON file\n","folder_path = '/usr/local/lib/python3.10/dist-packages/data/msc/msc/msc_personasummary'\n","\n","def createDataset(mode):\n","    s1_data_path = f\"{folder_path}/session_1/{mode}.txt\"\n","    s2_data_path = f\"{folder_path}/session_2/{mode}.txt\"\n","    s3_data_path = f\"{folder_path}/session_3/{mode}.txt\"\n","    s4_data_path = f\"{folder_path}/session_4/{mode}.txt\"\n","\n","    if mode == 'train':\n","        data_paths = [s1_data_path, s2_data_path, s3_data_path]\n","    else:\n","        data_paths = [s1_data_path, s2_data_path, s3_data_path, s4_data_path]\n","\n","    mode_X = []\n","    mode_y = []\n","    # 데이터 파일 열기\n","\n","    for data_path in data_paths:\n","        with open(data_path, 'r', encoding='utf-8') as f:\n","            for line in f:\n","                # 한 줄씩 읽기\n","                data = json.loads(line)\n","                train_data = \"\"\n","                agg_persona_list = []\n","                name1, name2 = getSpeakerNames()\n","                for i, utterance in enumerate(data['dialog']):\n","                    if utterance['id'] != 'bot_0' and utterance['id'] != 'bot_1': assert(0)\n","                    speaker_name = name1 if utterance['id'] == 'bot_0' else name2\n","                    text = utterance['text']\n","                    summary = utterance['agg_persona_list']\n","                    for i in range(len(summary)):\n","                        summary[i] = summary[i].replace('I', speaker_name)\n","                        summary[i] = summary[i].replace(\"'ve\", \"'s\")\n","\n","                    # 이어붙이기\n","                    train_data += f\"{speaker_name}: {text}\\r\\n\"\n","                    agg_persona_list.extend(summary)\n","                train_data = train_data.rstrip('\\r\\n')\n","                agg_persona_list = list(dict.fromkeys(agg_persona_list))\n","                joined_summaries = \" \".join(agg_persona_list)\n","                # print(train_data)\n","                # print(joined_summaries)\n","                mode_X.append(train_data)\n","                mode_y.append(joined_summaries)\n","    return mode_X, mode_y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9eaR3Y8Hr41M"},"outputs":[],"source":["train_X, train_y = createDataset(mode='train')\n","valid_X, valid_y = createDataset(mode='valid')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-tMGd8bO1NYw"},"outputs":[],"source":["train_X[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Q2bqKwaQ12BQ"},"outputs":[],"source":["train_y[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ibzuBCT9MMC"},"outputs":[],"source":["from datasets import Dataset\n","\n","train_dataset = Dataset.from_dict({'text':train_X, 'label':train_y})\n","valid_dataset = Dataset.from_dict({'text':valid_X, 'label':valid_y})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jqt-Xh5C-ZNL"},"outputs":[],"source":["print('Train Dataset Length : ', len(train_X))\n","print('Valid Dataset Length : ', len(valid_X))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eOUH_euD-hTq"},"outputs":[],"source":["prefix = 'summarize: '\n","def preprocess_data(sample):\n","    text = prefix + sample['text']\n","    #tokenize the dialogues\n","    model_inputs = tokenizer(text,  max_length=max_input, padding='max_length', truncation=True)\n","    #tokenize the summaries\n","    with tokenizer.as_target_tokenizer():\n","      targets = tokenizer(sample['label'], max_length=max_target, padding='max_length', truncation=True)\n","\n","    #set labels\n","    model_inputs['labels'] = targets['input_ids']\n","    #return the tokenized data\n","    #input_ids, attention_mask and labels\n","    return model_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LBgYd7Vx_mR6"},"outputs":[],"source":["tokenized_train_dataset = train_dataset.map(preprocess_data)\n","tokenized_valid_dataset = valid_dataset.map(preprocess_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xa1tcglhAh8n"},"outputs":[],"source":["tokenized_train_dataset[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MdptvtB0HZ_K"},"outputs":[],"source":["tokenized_train_dataset = tokenized_train_dataset.remove_columns(['text', 'label'])\n","tokenized_valid_dataset = tokenized_valid_dataset.remove_columns(['text', 'label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bU_8lQ69Ac40"},"outputs":[],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fJHUgkIlBh7j"},"outputs":[],"source":["batch_size = 8\n","model_name = \"Flan-T5-chat-summary\"\n","model_dir = f\"drive/MyDrive/Colab Notebooks/Metabuddy/Models/{model_name}\"\n","args = Seq2SeqTrainingArguments(\n","    model_dir,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=100,\n","    logging_strategy=\"steps\",\n","    logging_steps=100,\n","    save_strategy=\"steps\",\n","    save_steps=100,\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=5,\n","    predict_with_generate=True,\n","    fp16=False,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"rouge1\",\n","    report_to='wandb',\n","    push_to_hub=False,\n","    logging_dir=f\"{model_dir}/runs\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gnjtEGRtBpD7"},"outputs":[],"source":["label_pad_token_id = -100\n","\n","data_collator = DataCollatorForSeq2Seq(\n","    tokenizer,\n","    model=model,\n","    label_pad_token_id=label_pad_token_id,\n","    pad_to_multiple_of=8\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"r9JPMSvfCFBy"},"outputs":[],"source":["from datasets import load_metric\n","\n","metric = load_metric(\"rouge\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ojEYvDCxDGup"},"outputs":[],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"e_h2yG-lDHcy"},"outputs":[],"source":["id = wandb.util.generate_id()\n","print(id)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jWu037W1DLOL"},"outputs":[],"source":["wandb.init(project='Memory Extraction', # 실험기록을 관리한 프로젝트 이름\n","           entity='knkim', # 사용자명 또는 팀 이름\n","           id='mzm2f6b6',  # 실험에 부여된 고유 아이디\n","           name='plan-t5-chat-summary',    # 실험에 부여한 이름\n","          )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iAI7l06qG8qE"},"outputs":[],"source":["import numpy as np\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip()))\n","                      for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip()))\n","                      for label in decoded_labels]\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels,\n","                            use_stemmer=True)\n","\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id)\n","                      for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","\n","    return {k: round(v, 4) for k, v in result.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KeCqUMieHDP2"},"outputs":[],"source":["trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=args,\n","    train_dataset=tokenized_train_dataset,\n","    eval_dataset=tokenized_valid_dataset,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HUdD5dD9HQax"},"outputs":[],"source":["trainer.train(resume_from_checkpoint=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yW3f_oT5HTZZ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOAt9elAKYqQgKmNRPFcN4h","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}